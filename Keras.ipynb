{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Antes de comenzar estas lineas de código debe instalar las ultimas versiones de los paquetes*\n",
    "- Scikit-learn: Buscando en anaconda scikit-learn o poniendo en el terminal conda install scikit-learn o pip install scikit-learn ---> Más info en https://scikit-learn.org/stable/install.html\n",
    "- Pandas: Buscando en anaconda pandas o poniendo en el terminal conda install pandas o pip install pandas ---> Más info en https://pandas.pydata.org/docs/getting_started/index.html\n",
    "- Numpy: Buscando en anaconda numpy o poniendo en el terminal conda install numpy o pip install numpy ---> Más info en https://numpy.org/install/\n",
    "- Imbalanced-learn: Poniendo en el terminal conda install -c conda-forge imbalanced-learn o pip install -U imbalanced-learn ---> Más info en https://imbalanced-learn.readthedocs.io/en/stable/install.html\n",
    "- Pickle: Poniendo en el terminal pip install pickle ---> Más info si no te funciona en https://stackoverflow.com/questions/48477949/not-able-to-pip-install-pickle-in-python-3-6/48477988\n",
    "- seaborn: Buscando en anaconda seaborn o poniendo en el terminal pip install seaborn o conda install seaborn ---> Más info en https://seaborn.pydata.org/installing.html\n",
    "- matplotlib: Buscando en anaconda matplotlib o poniendo en el terminal pip install -U matplotlib ---> Más info en https://matplotlib.org/users/installing.html\n",
    "- Keras: Buscando e instalando en anaconda los módulos de tensorflow y keras. También se pueden instalar usando los comandos pip install tensorflow y pip install keras ---> Más infor en https://keras.io/about/\n",
    "\n",
    "Base de datos obtenida de: https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y balanceo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabecera: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "Ejemplo de caracteristicas: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "Forma de los datos de entrada al modelo: (284807, 30)\n",
      "Forma de las clases de salida: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "#Nombre del fichero que quiero leer\n",
    "datos = \"creditcard.csv\"\n",
    "\n",
    "#Inicialización de los arrays\n",
    "caracteristicas = []\n",
    "clase = []\n",
    "\n",
    "#Lectura de datos\n",
    "with open(datos) as f:\n",
    "    for i, linea in enumerate(f):\n",
    "        #Saltamos la cabecera del csv\n",
    "        if i == 0:\n",
    "            print(\"Cabecera:\", linea.strip())\n",
    "            continue  \n",
    "        #Introducimos los datos en los arrays de características\n",
    "        campos = linea.strip().split(\",\")\n",
    "        caracteristicas.append([float(v.replace('\"', \"\")) for v in campos[:-1]])\n",
    "        clase.append([int(campos[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"Ejemplo de caracteristicas:\", caracteristicas[-1])\n",
    "\n",
    "#Conversión de datos\n",
    "data = np.array(caracteristicas, dtype=\"float32\")\n",
    "target = np.array(clase, dtype=\"uint8\")\n",
    "\n",
    "#Pintamos la forma de los datos\n",
    "print(\"Forma de los datos de entrada al modelo:\", data.shape)\n",
    "print(\"Forma de las clases de salida:\", target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarjetas legales: 284315\n",
      "Tarjetas fraudulentas: 492\n"
     ]
    }
   ],
   "source": [
    "#Primero analizamos los datos\n",
    "\n",
    "#Inicializacion de la cuenta\n",
    "legal = 0\n",
    "fraude = 0\n",
    "\n",
    "#Cuenta de datos\n",
    "for x in range(target.shape[0]):\n",
    "    if target[x] == 0:\n",
    "        legal = legal + 1\n",
    "    else:\n",
    "        fraude = fraude + 1\n",
    "\n",
    "#Representación\n",
    "print(\"Tarjetas legales: \" + str(legal))\n",
    "print(\"Tarjetas fraudulentas: \" + str(fraude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarjetas legales balanceadas: 284315\n",
      "Tarjetas fraudulentas balanceadas: 284315\n"
     ]
    }
   ],
   "source": [
    "#Sobremuestreamos por la gran diferencia\n",
    "\n",
    "#Importamos los paquetes de sobremuestreo\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "#Generación de nuevas muestras sintéticas\n",
    "dataSmote, targetSmote = smote.fit_resample(data,target)\n",
    "\n",
    "#Volvemos a contar\n",
    "legal = 0\n",
    "fraude = 0\n",
    "\n",
    "#Cuenta de datos\n",
    "for x in range(targetSmote.shape[0]):\n",
    "    if targetSmote[x] == 0:\n",
    "        legal = legal + 1\n",
    "    else:\n",
    "        fraude = fraude + 1\n",
    "\n",
    "#Representación\n",
    "print(\"Tarjetas legales balanceadas: \" + str(legal))\n",
    "print(\"Tarjetas fraudulentas balanceadas: \" + str(fraude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de datos en conjunto de evaluación y conjunto de entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataTrain, dataTest, targetTrain, targetTest = train_test_split(dataSmote,targetSmote, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalización de los datos \n",
    "\n",
    "#Cálculo de la media\n",
    "mean = np.mean(dataTrain, axis=0)\n",
    "\n",
    "#Restamos a las características la media\n",
    "dataTrain -= mean\n",
    "dataTest -= mean\n",
    "\n",
    "#Cálculo de la desviación estándar\n",
    "std = np.std(dataTrain, axis=0)\n",
    "\n",
    "#Dividimos entre la desviación estándar\n",
    "dataTrain /= std\n",
    "dataTest /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del modelo con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "#Añadimos las capas de nuestra red neuronal (3 densas y dos de dropout)\n",
    "#Otra opcion seria añadirlas con add (próximo video)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        #Capa densa, la primera capa siempre tiene que especificar la forma de entrada\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(dataTrain.shape[-1],) #Nodos de la capa densa, y función de activación\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        #Capa de Dropout. Inactiva algunos de los nodos de la red para evitar el sobreentrenamiento\n",
    "        keras.layers.Dropout(0.3), #El atributo que se pone es el ratio de inactivación\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Vemos la forma de nuestro modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones de las métricas (sacadas de internet: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model)\n",
    "from keras import backend as K\n",
    "\n",
    "#Funciones de las métricas\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426472 samples, validate on 142158 samples\n",
      "Epoch 1/30\n",
      "426472/426472 [==============================] - 31s 73us/sample - loss: 0.0448 - acc: 0.9839 - f1_m: 0.9844 - precision_m: 0.9878 - recall_m: 0.9819 - val_loss: 0.0089 - val_acc: 0.9974 - val_f1_m: 0.9974 - val_precision_m: 0.9976 - val_recall_m: 0.9972\n",
      "Epoch 2/30\n",
      "426472/426472 [==============================] - 29s 67us/sample - loss: 0.0084 - acc: 0.9977 - f1_m: 0.9977 - precision_m: 0.9970 - recall_m: 0.9984 - val_loss: 0.0040 - val_acc: 0.9990 - val_f1_m: 0.9990 - val_precision_m: 0.9980 - val_recall_m: 1.0000\n",
      "Epoch 3/30\n",
      "426472/426472 [==============================] - 31s 73us/sample - loss: 0.0066 - acc: 0.9984 - f1_m: 0.9984 - precision_m: 0.9978 - recall_m: 0.9990 - val_loss: 0.0037 - val_acc: 0.9992 - val_f1_m: 0.9992 - val_precision_m: 0.9984 - val_recall_m: 0.9999\n",
      "Epoch 4/30\n",
      "426472/426472 [==============================] - 32s 74us/sample - loss: 0.0052 - acc: 0.9987 - f1_m: 0.9987 - precision_m: 0.9981 - recall_m: 0.9992 - val_loss: 0.0047 - val_acc: 0.9986 - val_f1_m: 0.9987 - val_precision_m: 0.9992 - val_recall_m: 0.9981\n",
      "Epoch 5/30\n",
      "426472/426472 [==============================] - 41s 97us/sample - loss: 0.0045 - acc: 0.9989 - f1_m: 0.9989 - precision_m: 0.9985 - recall_m: 0.9994 - val_loss: 0.0041 - val_acc: 0.9990 - val_f1_m: 0.9990 - val_precision_m: 0.9994 - val_recall_m: 0.9986\n",
      "Epoch 6/30\n",
      "426472/426472 [==============================] - 39s 92us/sample - loss: 0.0035 - acc: 0.9991 - f1_m: 0.9991 - precision_m: 0.9988 - recall_m: 0.9994 - val_loss: 0.0030 - val_acc: 0.9992 - val_f1_m: 0.9992 - val_precision_m: 0.9986 - val_recall_m: 0.9998\n",
      "Epoch 7/30\n",
      "426472/426472 [==============================] - 34s 79us/sample - loss: 0.0045 - acc: 0.9990 - f1_m: 0.9990 - precision_m: 0.9986 - recall_m: 0.9993 - val_loss: 0.0031 - val_acc: 0.9993 - val_f1_m: 0.9993 - val_precision_m: 0.9994 - val_recall_m: 0.9992\n",
      "Epoch 8/30\n",
      "426472/426472 [==============================] - 31s 72us/sample - loss: 0.0045 - acc: 0.9990 - f1_m: 0.9990 - precision_m: 0.9987 - recall_m: 0.9993 - val_loss: 0.0023 - val_acc: 0.9995 - val_f1_m: 0.9995 - val_precision_m: 0.9989 - val_recall_m: 1.0000\n",
      "Epoch 9/30\n",
      "426472/426472 [==============================] - 34s 79us/sample - loss: 0.0034 - acc: 0.9993 - f1_m: 0.9993 - precision_m: 0.9990 - recall_m: 0.9995 - val_loss: 0.0033 - val_acc: 0.9993 - val_f1_m: 0.9993 - val_precision_m: 0.9992 - val_recall_m: 0.9994\n",
      "Epoch 10/30\n",
      "426472/426472 [==============================] - 36s 85us/sample - loss: 0.0027 - acc: 0.9994 - f1_m: 0.9994 - precision_m: 0.9992 - recall_m: 0.9996 - val_loss: 0.0017 - val_acc: 0.9997 - val_f1_m: 0.9997 - val_precision_m: 0.9994 - val_recall_m: 1.0000\n",
      "Epoch 11/30\n",
      "426472/426472 [==============================] - 33s 79us/sample - loss: 0.0050 - acc: 0.9990 - f1_m: 0.9990 - precision_m: 0.9987 - recall_m: 0.9992 - val_loss: 0.0130 - val_acc: 0.9983 - val_f1_m: 0.9983 - val_precision_m: 0.9990 - val_recall_m: 0.9976\n",
      "Epoch 12/30\n",
      "426472/426472 [==============================] - 34s 80us/sample - loss: 0.0124 - acc: 0.9977 - f1_m: 0.9977 - precision_m: 0.9970 - recall_m: 0.9984 - val_loss: 0.0064 - val_acc: 0.9994 - val_f1_m: 0.9994 - val_precision_m: 0.9988 - val_recall_m: 1.0000\n",
      "Epoch 13/30\n",
      "426472/426472 [==============================] - 34s 79us/sample - loss: 0.0060 - acc: 0.9988 - f1_m: 0.9988 - precision_m: 0.9984 - recall_m: 0.9992 - val_loss: 0.0022 - val_acc: 0.9995 - val_f1_m: 0.9995 - val_precision_m: 0.9991 - val_recall_m: 1.0000\n",
      "Epoch 14/30\n",
      "426472/426472 [==============================] - 37s 88us/sample - loss: 0.0040 - acc: 0.9991 - f1_m: 0.9991 - precision_m: 0.9987 - recall_m: 0.9995 - val_loss: 0.0028 - val_acc: 0.9994 - val_f1_m: 0.9994 - val_precision_m: 0.9988 - val_recall_m: 1.0000\n",
      "Epoch 15/30\n",
      "426472/426472 [==============================] - 40s 93us/sample - loss: 0.0030 - acc: 0.9995 - f1_m: 0.9994 - precision_m: 0.9992 - recall_m: 0.9997 - val_loss: 0.0020 - val_acc: 0.9995 - val_f1_m: 0.9995 - val_precision_m: 0.9994 - val_recall_m: 0.9997\n",
      "Epoch 16/30\n",
      "426472/426472 [==============================] - 33s 77us/sample - loss: 0.0031 - acc: 0.9995 - f1_m: 0.9995 - precision_m: 0.9993 - recall_m: 0.9996 - val_loss: 0.0025 - val_acc: 0.9994 - val_f1_m: 0.9994 - val_precision_m: 0.9990 - val_recall_m: 0.9997\n",
      "Epoch 17/30\n",
      "426472/426472 [==============================] - 30s 71us/sample - loss: 0.0028 - acc: 0.9993 - f1_m: 0.9993 - precision_m: 0.9991 - recall_m: 0.9995 - val_loss: 0.0101 - val_acc: 0.9967 - val_f1_m: 0.9968 - val_precision_m: 0.9935 - val_recall_m: 1.0000\n",
      "Epoch 18/30\n",
      "426472/426472 [==============================] - 30s 71us/sample - loss: 0.0022 - acc: 0.9995 - f1_m: 0.9995 - precision_m: 0.9993 - recall_m: 0.9998 - val_loss: 0.0025 - val_acc: 0.9994 - val_f1_m: 0.9994 - val_precision_m: 0.9988 - val_recall_m: 0.9999\n",
      "Epoch 19/30\n",
      "426472/426472 [==============================] - 31s 74us/sample - loss: 0.0018 - acc: 0.9996 - f1_m: 0.9996 - precision_m: 0.9994 - recall_m: 0.9998 - val_loss: 0.0014 - val_acc: 0.9997 - val_f1_m: 0.9997 - val_precision_m: 0.9994 - val_recall_m: 1.0000\n",
      "Epoch 20/30\n",
      "426472/426472 [==============================] - 30s 71us/sample - loss: 0.0021 - acc: 0.9996 - f1_m: 0.9996 - precision_m: 0.9994 - recall_m: 0.9998 - val_loss: 0.0018 - val_acc: 0.9997 - val_f1_m: 0.9997 - val_precision_m: 0.9994 - val_recall_m: 1.0000\n",
      "Epoch 21/30\n",
      "426472/426472 [==============================] - 31s 73us/sample - loss: 0.0054 - acc: 0.9990 - f1_m: 0.9990 - precision_m: 0.9988 - recall_m: 0.9992 - val_loss: 0.0049 - val_acc: 0.9997 - val_f1_m: 0.9997 - val_precision_m: 0.9994 - val_recall_m: 1.0000\n",
      "Epoch 22/30\n",
      "426472/426472 [==============================] - 31s 72us/sample - loss: 0.0083 - acc: 0.9993 - f1_m: 0.9993 - precision_m: 0.9991 - recall_m: 0.9995 - val_loss: 0.0019 - val_acc: 0.9995 - val_f1_m: 0.9996 - val_precision_m: 0.9991 - val_recall_m: 1.0000\n",
      "Epoch 23/30\n",
      "426472/426472 [==============================] - 38s 89us/sample - loss: 0.0029 - acc: 0.9994 - f1_m: 0.9994 - precision_m: 0.9992 - recall_m: 0.9997 - val_loss: 0.0020 - val_acc: 0.9996 - val_f1_m: 0.9996 - val_precision_m: 0.9992 - val_recall_m: 1.0000\n",
      "Epoch 24/30\n",
      "426472/426472 [==============================] - 31s 73us/sample - loss: 0.0029 - acc: 0.9995 - f1_m: 0.9995 - precision_m: 0.9993 - recall_m: 0.9998 - val_loss: 0.0059 - val_acc: 0.9995 - val_f1_m: 0.9996 - val_precision_m: 0.9991 - val_recall_m: 1.0000\n",
      "Epoch 25/30\n",
      "426472/426472 [==============================] - 33s 78us/sample - loss: 0.0035 - acc: 0.9995 - f1_m: 0.9995 - precision_m: 0.9993 - recall_m: 0.9997 - val_loss: 0.0021 - val_acc: 0.9996 - val_f1_m: 0.9996 - val_precision_m: 0.9994 - val_recall_m: 0.9998\n",
      "Epoch 26/30\n",
      "426472/426472 [==============================] - 29s 68us/sample - loss: 0.0122 - acc: 0.9992 - f1_m: 0.9991 - precision_m: 0.9990 - recall_m: 0.9993 - val_loss: 0.0139 - val_acc: 0.9965 - val_f1_m: 0.9965 - val_precision_m: 0.9977 - val_recall_m: 0.9952\n",
      "Epoch 27/30\n",
      "426472/426472 [==============================] - 31s 72us/sample - loss: 0.0061 - acc: 0.9988 - f1_m: 0.9989 - precision_m: 0.9986 - recall_m: 0.9991 - val_loss: 0.0017 - val_acc: 0.9996 - val_f1_m: 0.9997 - val_precision_m: 0.9993 - val_recall_m: 1.0000\n",
      "Epoch 28/30\n",
      "426472/426472 [==============================] - 31s 74us/sample - loss: 0.0026 - acc: 0.9995 - f1_m: 0.9995 - precision_m: 0.9993 - recall_m: 0.9997 - val_loss: 0.0016 - val_acc: 0.9997 - val_f1_m: 0.9997 - val_precision_m: 0.9995 - val_recall_m: 0.9999\n",
      "Epoch 29/30\n",
      "426472/426472 [==============================] - 44s 103us/sample - loss: 0.0019 - acc: 0.9997 - f1_m: 0.9997 - precision_m: 0.9995 - recall_m: 0.9999 - val_loss: 0.0022 - val_acc: 0.9995 - val_f1_m: 0.9995 - val_precision_m: 0.9991 - val_recall_m: 1.0000\n",
      "Epoch 30/30\n",
      "426472/426472 [==============================] - 64s 150us/sample - loss: 0.0026 - acc: 0.9995 - f1_m: 0.9995 - precision_m: 0.9992 - recall_m: 0.9998 - val_loss: 0.0023 - val_acc: 0.9995 - val_f1_m: 0.9995 - val_precision_m: 0.9991 - val_recall_m: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed05952c90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos el modelo\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=['accuracy',f1_m,precision_m, recall_m]\n",
    ") #Compilamos el modelo con su optimizador, la forma en la que actualizamos los pesos (minimización) y en base a qué métricas\n",
    "\n",
    "#Lo entrenamos con los datos de entrenamiento\n",
    "model.fit(\n",
    "    dataTrain,\n",
    "    targetTrain,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    "    validation_data=(dataTest, targetTest),\n",
    ")#Conjuntos de entrenamientos y evaluación, numero de muestras en la propagación hacia atrás, \n",
    "#numero de iteraciones para mejorar el modelo, la verbosidad y los conjuntos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas\n",
    "#Conjunto de entrenamiento\n",
    "print(\"Datos sobre el entrenamiento\")\n",
    "loss, accuracy,f1_score, precision, recall = model.evaluate(dataTrain, targetTrain, verbose=False)\n",
    "print(\"Exactitud de entrenamiento: {:.4f}\".format(accuracy))\n",
    "print(\"F1 de entrenamiento: {:.4f}\".format(f1_score))\n",
    "print(\"Precisión de entrenamiento: {:.4f}\".format(precision))\n",
    "print(\"Memoria de entrenamiento: {:.4f}\".format(recall))\n",
    "\n",
    "#Conjunto de evaluación\n",
    "print()\n",
    "print(\"Datos sobre la evaluación\")\n",
    "loss, accuracy,f1_score, precision, recall = model.evaluate(dataTest, targetTest, verbose=False)\n",
    "print(\"Exactitud de evaluación: {:.4f}\".format(accuracy))\n",
    "print(\"F1 de evaluación: {:.4f}\".format(f1_score))\n",
    "print(\"Precisión de evaluación: {:.4f}\".format(precision))\n",
    "print(\"Memoria de evaluación: {:.4f}\".format(recall))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sobre las guías de usuario de estos 3 paquetes puede encontrar todas sus funcionalidades. En los siguientes código usaremos más funciones de ellos:\n",
    "- Scikit-learn: https://scikit-learn.org/stable/user_guide.html\n",
    "- Pandas: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "- Numpy: https://numpy.org/doc/stable/\n",
    "- Imbalanced-learn: https://imbalanced-learn.readthedocs.io/en/stable/user_guide.html\n",
    "- Pickle: https://docs.python.org/3/library/pickle.html\n",
    "- Seaborn: https://seaborn.pydata.org/installing.html\n",
    "- Matplotlib: https://matplotlib.org/users/index.html\n",
    "- Keras: https://keras.io/guides/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
