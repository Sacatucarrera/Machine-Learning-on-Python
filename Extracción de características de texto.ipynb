{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Antes de comenzar estas lineas de código debe instalar las ultimas versiones de los paquetes*\n",
    "- Scikit-learn: Buscando en anaconda scikit-learn o poniendo en el terminal conda install scikit-learn o pip install scikit-learn ---> Más info en https://scikit-learn.org/stable/install.html\n",
    "- Pandas: Buscando en anaconda pandas o poniendo en el terminal conda install pandas o pip install pandas ---> Más info en https://pandas.pydata.org/docs/getting_started/index.html\n",
    "- Numpy: Buscando en anaconda numpy o poniendo en el terminal conda install numpy o pip install numpy ---> Más info en https://numpy.org/install/\n",
    "- Imbalanced-learn: Poniendo en el terminal conda install -c conda-forge imbalanced-learn o pip install -U imbalanced-learn ---> Más info en https://imbalanced-learn.readthedocs.io/en/stable/install.html\n",
    "- Pickle: Poniendo en el terminal pip install pickle ---> Más info si no te funciona en https://stackoverflow.com/questions/48477949/not-able-to-pip-install-pickle-in-python-3-6/48477988\n",
    "- seaborn: Buscando en anaconda seaborn o poniendo en el terminal pip install seaborn o conda install seaborn ---> Más info en https://seaborn.pydata.org/installing.html\n",
    "- matplotlib: Buscando en anaconda matplotlib o poniendo en el terminal pip install -U matplotlib ---> Más info en https://matplotlib.org/users/installing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquetes para lectura y recuento\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "\n",
    "#Primero importamos los datos que vamos a leer\n",
    "news = fetch_20newsgroups()\n",
    "\n",
    "#Pasamos los datos a un DataFrame (datos en pandas)\n",
    "data = pd.DataFrame(news['data'], columns = ['News'])\n",
    "target = pd.DataFrame(news['target'], columns = ['Type'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data#['News'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extacción de características (Siempre antes de sobremuestrear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Inicialización de los vectores de extracción de características\n",
    "#CountVectorizer\n",
    "vectCV = CountVectorizer(max_features = 400).fit(data['News']) #stop_words = ['palabras', 'que', 'no', 'cuentan']\n",
    "#TfidfVectorizer. \n",
    "vectTf = TfidfVectorizer(min_df = 3,use_idf = False, smooth_idf = False).fit(data['News']) \n",
    "\n",
    "#Obtención de las matrices de características\n",
    "X_vectorizedCV = vectCV.transform(data['News'])\n",
    "X_vectorizedTf = vectTf.transform(data['News'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorizedCV\n",
    "#print(X_vectorizedCV.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorizedTf\n",
    "#print(X_vectorizedTf.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobremuestreo y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobremuestreo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los paquetes de sobremuestreo\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "#Generación de nuevas muestras sintéticas\n",
    "dataSmoteCV, targetSmoteCV = smote.fit_resample(X_vectorizedCV,target['Type'])\n",
    "dataSmoteTf, targetSmoteTf = smote.fit_resample(X_vectorizedTf,target['Type'])\n",
    "print(dataSmoteCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de los conjuntos de evaluación y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataTrainCV, dataTestCV, targetTrainCV, targetTestCV = train_test_split(dataSmoteCV,targetSmoteCV, random_state = 0)\n",
    "dataTrainTf, dataTestTf, targetTrainTf, targetTestTf = train_test_split(dataSmoteTf,targetSmoteTf, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquete\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Inicialización.\n",
    "modelDTSCV = DecisionTreeClassifier()\n",
    "modelDTSTf = DecisionTreeClassifier()\n",
    "\n",
    "#Entrenamiento\n",
    "modelDTSCV.fit(dataTrainCV, targetTrainCV)\n",
    "modelDTSTf.fit(dataTrainTf, targetTrainTf)\n",
    "\n",
    "#Predicción \n",
    "targetPredDTSCV = modelDTSCV.predict(dataTestCV)\n",
    "targetPredDTSTf = modelDTSTf.predict(dataTestTf)\n",
    "\n",
    "#Evaluación\n",
    "\n",
    "#Paquete\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print('Exactitud árbol CV: ', accuracy_score(targetPredDTSCV,targetTestCV))\n",
    "print('Exactitud árbol Tfidf: ', accuracy_score(targetPredDTSTf,targetTestTf))\n",
    "print('Memoria árbol CV: ', recall_score(targetPredDTSCV,targetTestCV,average='weighted'))\n",
    "print('Memoria árbol Tfidf: ', recall_score(targetPredDTSTf,targetTestTf,average='weighted'))\n",
    "print('Precisión árbol CV: ', precision_score(targetPredDTSCV,targetTestCV,average='weighted'))\n",
    "print('Precisión árbol Tfidf: ', precision_score(targetPredDTSTf,targetTestTf,average='weighted'))\n",
    "print('Puntuación F1 árbol CV: ', f1_score(targetPredDTSCV,targetTestCV,average='weighted'))\n",
    "print('Puntuación F1 árbol Tfidf: ', f1_score(targetPredDTSTf,targetTestTf,average='weighted'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sobre las guías de usuario de estos 3 paquetes puede encontrar todas sus funcionalidades. En los siguientes código usaremos más funciones de ellos:\n",
    "- Scikit-learn: https://scikit-learn.org/stable/user_guide.html\n",
    "- Pandas: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "- Numpy: https://numpy.org/doc/stable/\n",
    "- Imbalanced-learn: https://imbalanced-learn.readthedocs.io/en/stable/user_guide.html\n",
    "- Pickle: https://docs.python.org/3/library/pickle.html\n",
    "- Seaborn: https://seaborn.pydata.org/installing.html\n",
    "- Matplotlib: https://matplotlib.org/users/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
