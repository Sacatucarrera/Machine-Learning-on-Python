{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de una red neuronal seguida de SVC y modelos de HMM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Librerías y módulos de Python necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de la base de datos\n",
    "import pandas as pd\n",
    "\n",
    "#Preprocesamiento de los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "#Evaluación de la actuación del modelo\n",
    "from sklearn import metrics\n",
    "\n",
    "#Modelos HMM\n",
    "import seqlearn.hmm\n",
    "from seqlearn.hmm import MultinomialHMM\n",
    "import seqlearn.perceptron\n",
    "from seqlearn.perceptron import StructuredPerceptron\n",
    "from pomegranate import *\n",
    "\n",
    "#Carga y almacenamiento de modelos\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "#Preprocesamiento de los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import float64\n",
    "\n",
    "#Redes neuronales\n",
    "from keras import backend as K\n",
    "from sklearn import svm\n",
    "import keras.losses\n",
    "import keras.metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "keras.metrics.f1_m = f1_m\n",
    "keras.metrics.precision_m = precision_m\n",
    "keras.metrics.recall_m = recall_m"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Prueba de las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;31mKeyError\u001b[0m: 5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pomegranate.hmm.HiddenMarkovModel._labeled_summarize'\n",
      "KeyError: 5\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;31mKeyError\u001b[0m: 5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pomegranate.hmm.HiddenMarkovModel._labeled_summarize'\n",
      "KeyError: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36714957313452934\n",
      "0.505706555397713\n",
      "0.05769344208046942\n"
     ]
    }
   ],
   "source": [
    "#Lectura del fichero de datos CSV. Separación por ; e ignorando el espacio inicial\n",
    "data = pd.read_csv('database_speech.csv', sep = ';', skipinitialspace = True)\n",
    "\n",
    "#Parámetros de interés\n",
    "embedding_dim = 300 #Tamaño del vocabulario de incrustación\n",
    "vocab_size = 1860 #Tamaño del vocabulario de la red neuronal\n",
    "maxlen = 200 #Máxima longitud del padding\n",
    "\n",
    "#Preprocesado de datos\n",
    "X_data, y_data = data['Transcription'],data['Phase']\n",
    "#Tokenización\n",
    "tokenizer = Tokenizer(num_words=500)\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "X = tokenizer.texts_to_sequences(X_data)\n",
    "#Padding\n",
    "X_pad = pad_sequences(X, padding='post', maxlen=maxlen)\n",
    "#Balanceo\n",
    "#ROS\n",
    "ros = RandomOverSampler()\n",
    "#SMOTE\n",
    "smote = SMOTE()\n",
    "X_SM, y_SM = smote.fit_resample(X_pad,y_data)\n",
    "X_RO, y_RO = ros.fit_resample(X_pad,y_data)\n",
    "#División en conjunto de entrenamiento y conjunto de evaluación\n",
    "X_trainSM, X_testSM, y_trainSM, y_testSM = train_test_split(X_SM, y_SM)\n",
    "X_trainRO, X_testRO, y_trainRO, y_testRO = train_test_split(X_RO, y_RO)\n",
    "\n",
    "#Carga del modelo neuronal extractor de características\n",
    "import pickle\n",
    "filename = 'modelFE.model'\n",
    "sModel = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#Extracción de las características extraidas por las capas (Descomentar el método de balanceo que se desee utilizar)\n",
    "inp = sModel.input      \n",
    "outputs = [layer.output for layer in sModel.layers]          \n",
    "functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    \n",
    "#Características del entrenamiento\n",
    "layer_outs = [func([X_trainSM, 1.]) for func in functors]\n",
    "#layer_outs = [func([X_trainRO, 1.]) for func in functors]\n",
    "#Características de la evaluación\n",
    "layer_outs_test = [func([X_testSM, 1.]) for func in functors]\n",
    "#layer_outs_test = [func([X_testRO, 1.]) for func in functors]\n",
    "\n",
    "#Generación del mejor estimador y ajuste a sus características\n",
    "clf = svm.SVC(C = 1, decision_function_shape = 'ovo', degree = 1, gamma = 'scale', kernel = 'rbf', probability = True, shrinking = True, tol = 0.01)\n",
    "clf.fit(layer_outs[2][0], y_trainSM)\n",
    "#clf.fit(layer_outs[2][0], y_trainRO)\n",
    "predictions=clf.predict_proba(layer_outs[2][0])\n",
    "pred=clf.predict_proba(layer_outs_test[2][0])\n",
    "#Ajuste de los valores obtenidos\n",
    "pred = float64(pred)\n",
    "\n",
    "#Modelos HMM\n",
    "#Inicialización\n",
    "modelHMM1 = MultinomialHMM(alpha = 15,decode = 'bestfirst')\n",
    "modelHMM2 = StructuredPerceptron(lr_exponent = 0.05,decode = 'viterbi', max_iter = 1000) #Modificar labels si cambia el balanceo\n",
    "modelHMM3 = HiddenMarkovModel.from_samples(DirichletDistribution, n_components = 8, X = [predictions], labels = [y_trainSM], algorithm = 'labeled',name = 'HMM', n_jobs = -1)\n",
    "#Ajuste a los datos de entrenamiento\n",
    "modelHMM1.fit(predictions,y_trainSM,[len(y_trainSM)])\n",
    "modelHMM2.fit(predictions,y_trainSM,[len(y_trainSM)])\n",
    "#modelHMM1.fit(predictions,y_trainRO,[len(y_trainRO)])\n",
    "#modelHMM2.fit(predictions,y_trainRO,[len(y_trainRO)])\n",
    "#Predicción\n",
    "y_pred1 = modelHMM1.predict(pred,[len(y_testSM)])\n",
    "y_pred2 = modelHMM2.predict(pred,[len(y_testSM)])\n",
    "y_pred3 = modelHMM3.predict(pred, algorithm = 'labeled')\n",
    "#y_pred1 = modelHMM1.predict(pred,[len(y_testRO)])\n",
    "#y_pred2 = modelHMM2.predict(pred,[len(y_testRO)])\n",
    "#Elimina el estado de inicio generado por el modeloHMM3 por defecto\n",
    "y_pred3.pop(0)\n",
    "#Evaluación\n",
    "print(metrics.f1_score(y_testSM,y_pred1,average = 'weighted'))\n",
    "print(metrics.f1_score(y_testSM,y_pred2,average = 'weighted'))\n",
    "print(metrics.f1_score(y_testSM,y_pred3,average = 'weighted'))\n",
    "#print(metrics.f1_score(y_testRO,y_pred1,average = 'weighted'))\n",
    "#print(metrics.f1_score(y_testRO,y_pred2,average = 'weighted'))\n",
    "#print(metrics.f1_score(y_testRO,y_pred3,average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
