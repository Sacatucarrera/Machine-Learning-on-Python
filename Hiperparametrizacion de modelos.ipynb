{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Antes de comenzar estas lineas de código debe instalar las ultimas versiones de los paquetes*\n",
    "- Scikit-learn: Buscando en anaconda scikit-learn o poniendo en el terminal conda install scikit-learn o pip install scikit-learn ---> Más info en https://scikit-learn.org/stable/install.html\n",
    "- Pandas: Buscando en anaconda pandas o poniendo en el terminal conda install pandas o pip install pandas ---> Más info en https://pandas.pydata.org/docs/getting_started/index.html\n",
    "- Numpy: Buscando en anaconda numpy o poniendo en el terminal conda install numpy o pip install numpy ---> Más info en https://numpy.org/install/\n",
    "- Imbalanced-learn: Poniendo en el terminal conda install -c conda-forge imbalanced-learn o pip install -U imbalanced-learn ---> Más info en https://imbalanced-learn.readthedocs.io/en/stable/install.html\n",
    "- Pickle: Poniendo en el terminal pip install pickle ---> Más info si no te funciona en https://stackoverflow.com/questions/48477949/not-able-to-pip-install-pickle-in-python-3-6/48477988\n",
    "- seaborn: Buscando en anaconda seaborn o poniendo en el terminal pip install seaborn o conda install seaborn ---> Más info en https://seaborn.pydata.org/installing.html\n",
    "- matplotlib: Buscando en anaconda matplotlib o poniendo en el terminal pip install -U matplotlib ---> Más info en https://matplotlib.org/users/installing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y balanceo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquetes para lectura y recuento\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "#Primero importamos los datos que vamos a leer\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "#Pasamos los datos a un DataFrame (datos en pandas)\n",
    "data = pd.DataFrame(cancer_data['data'], columns = cancer_data['feature_names'])\n",
    "target = pd.DataFrame(cancer_data['target'],columns = ['Tumor Type'])\n",
    "\n",
    "#Si quisieramos coger solo unas características\n",
    "#data = data[['mean radius', 'mean texture']] \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los paquetes de sobremuestreo\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "#Generación de nuevas muestras sintéticas\n",
    "dataSmote, targetSmote = smote.fit_resample(data,target)\n",
    "\n",
    "#Representación\n",
    "dataSmote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de los conjuntos de evaluación y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataTrain, dataTest, targetTrain, targetTest = train_test_split(data,target, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametrización del árbol de decisión"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Repasemos el arbol de decisión creado en videos anteriores, sin hiperparametrización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquete\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Inicialización.\n",
    "modelDTS = DecisionTreeClassifier()\n",
    "\n",
    "#Entrenamiento\n",
    "modelDTS.fit(dataTrain, targetTrain)\n",
    "\n",
    "#Predicción \n",
    "targetPredDTS = modelDTS.predict(dataTest)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y veamos ahora como podemos hiperparametrizarlo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el paquete de la búsqueda Grid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Declaramos las variables que van a hiperparametrizarse\n",
    "param_grid = [{'criterion': ['gini','entropy'],\n",
    "              'max_depth': [None, 50, 100, 200, 500],\n",
    "              'min_samples_split': [2,3,4]}]\n",
    "\n",
    "#Inicializamos la búsqueda grid\n",
    "grid = GridSearchCV(modelDTS, param_grid, cv = 5, n_jobs = -1, scoring = 'precision')\n",
    "\n",
    "#Entrenamos con los datos de entreno...\n",
    "grid.fit(dataTrain,targetTrain)\n",
    "\n",
    "#Pintamos los resultados:\n",
    "print(\"Mejores parámetros: \")\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Puntuaciones: \")\n",
    "print(grid.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ahora podemos predecir los valores con el mejor estimador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetPredGrid = grid.predict(dataTest)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y comparamos los resultados con las métricas explicadas con anterioridad\n",
    "\n",
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquetes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Obtención de la matriz\n",
    "arrayDTS = confusion_matrix(targetPredDTS, targetTest)\n",
    "arrayGrid = confusion_matrix(targetPredGrid, targetTest)\n",
    "df_cmDTS = pd.DataFrame(arrayDTS)\n",
    "df_cmGrid = pd.DataFrame(arrayGrid)\n",
    "\n",
    "#Representación de la matriz de confusión\n",
    "sn.set(font_scale=1)\n",
    "plt.title('Árbol por defecto')\n",
    "plt.show(sn.heatmap(df_cmDTS, annot=True, annot_kws={\"size\": 16}, cmap = 'Reds')) \n",
    "plt.title('Árbol hiperparametrizado')\n",
    "plt.show(sn.heatmap(df_cmGrid, annot=True, annot_kws={\"size\": 16}, cmap = 'Reds')) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exactitud, precisión, memoria y puntuación F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquete\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print('Exactitud árbol por defecto: ', accuracy_score(targetPredDTS,targetTest))\n",
    "print('Exactitud árbol hiperparametrizado: ', accuracy_score(targetPredGrid,targetTest))\n",
    "print('Memoria árbol por defecto: ', recall_score(targetPredDTS,targetTest))\n",
    "print('Memoria árbol hiperparametrizado: ', recall_score(targetPredGrid,targetTest))\n",
    "print('Precisión árbol por defecto: ', precision_score(targetPredDTS,targetTest))\n",
    "print('Precisión árbol hiperparametrizado: ', precision_score(targetPredGrid,targetTest))\n",
    "print('Puntuación F1 árbol por defecto: ', f1_score(targetPredDTS,targetTest))\n",
    "print('Puntuación F1 árbol hiperparametrizado: ', f1_score(targetPredGrid,targetTest))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Curva ROC y área por debajo de la curva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paquete\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Obtención de las probabilidades de los datos de entrada\n",
    "targetPredProbaDTS = modelDTS.predict_proba(dataTest)\n",
    "targetPredProbaGrid = grid.predict_proba(dataTest)\n",
    "\n",
    "#Obtención curva ROC\n",
    "memDTS, unomenosespecDTS, umbralDTS = roc_curve(targetTest, targetPredProbaDTS[:,1])\n",
    "memGrid, unomenosespecGrid, umbralGrid = roc_curve(targetTest, targetPredProbaGrid[:,1])\n",
    "\n",
    "#Pintar Curva ROC\n",
    "plt.title('ROC árboles')\n",
    "plt.plot(memDTS, unomenosespecDTS,linestyle = ':')\n",
    "plt.plot(memGrid, unomenosespecGrid, linestyle = '-.')\n",
    "plt.plot([0,1],[0,1], linestyle = '--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.xlabel('1 - especificidad')\n",
    "plt.ylabel('memoria')\n",
    "plt.show()\n",
    "\n",
    "print('Área por debajo de la curva del árbol por defecto: ', roc_auc_score(targetTest,targetPredProbaDTS[:,1]))\n",
    "print('Área por debajo de la curva del árbol hiperparametrizado: ', roc_auc_score(targetTest,targetPredProbaGrid[:,1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sobre las guías de usuario de estos 3 paquetes puede encontrar todas sus funcionalidades. En los siguientes código usaremos más funciones de ellos:\n",
    "- Scikit-learn: https://scikit-learn.org/stable/user_guide.html\n",
    "- Pandas: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "- Numpy: https://numpy.org/doc/stable/\n",
    "- Imbalanced-learn: https://imbalanced-learn.readthedocs.io/en/stable/user_guide.html\n",
    "- Pickle: https://docs.python.org/3/library/pickle.html\n",
    "- Seaborn: https://seaborn.pydata.org/installing.html\n",
    "- Matplotlib: https://matplotlib.org/users/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
